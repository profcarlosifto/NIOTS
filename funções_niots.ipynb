{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "funções_niots.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1K5D1TxaGdh0bK3n6eloT0lmc8rLqiRVj",
      "authorship_tag": "ABX9TyP9PIwA1jnq2X6i2hkbDR9y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/profcarlosifto/NIOTS/blob/main/fun%C3%A7%C3%B5es_niots.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ClNgbMRSgq1"
      },
      "source": [
        "# **Nature Inspired Optmization Tools for SVM - NIOTS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbngs1FYKwZa"
      },
      "source": [
        "#Funções auxiliares para emprego no *NIOTS*\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjBSNYWIAHvA"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AK7_DKfbLZPX"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7h_5oQT8w7z"
      },
      "source": [
        "def calc_R2(real1,est1):\n",
        "  real = np.array(real1)\n",
        "  est = np.array(est1)\n",
        "# calcula o R2 - coeficiente de correlação múltipla\n",
        "    \n",
        "  SSE=sum((real - est) ** 2)\n",
        "# calc_R2.m:4\n",
        "    \n",
        "  avg_real=np.mean(real)\n",
        "# calc_R2.m:6\n",
        "  sum2=sum((real - avg_real) ** 2)\n",
        "# calc_R2.m:8\n",
        "    # R2 = 1 - ( sum((real-est).^2) ./ sum((aux_R2).^2));\n",
        "  R2=1 - SSE / sum2\n",
        "# calc_R2.m:11\n",
        "  return R2"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7L7l43eG8_XZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2f0523a-e4f0-410a-ef13-e95af79aada0"
      },
      "source": [
        "print (calc_R2([2, 3, 1],[2.1, 2.8, 1.2]))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.955\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vH-uYamYL3E3"
      },
      "source": [
        " A função gera uma matriz de números aleatórios conforme a definição de\n",
        " Symetric Latin Hypercube. \n",
        " Esta função é baseada no pseudo código do artigo:\n",
        " *\"A differential evolution  algorithm with self-adaptive strategy and \n",
        " control parameters based on symmetric Latin hypercube design for\n",
        " unconstrained optimization problems\"*\n",
        " \n",
        " Parameters:\n",
        "         \n",
        "         NP -> number of population individuals\n",
        "\n",
        "         d  -> number of decision variables (features)\n",
        " Return: \n",
        "            \n",
        "          m   -> matriz SLHD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TY-vzrAcBUO3"
      },
      "source": [
        "def SLHD(NP,d):\n",
        "# A função gera uma matriz de números aleatórios conforme a definição de\n",
        "# Symetric Latin Hypercube. \n",
        "# Esta função é baseada no pseudo código do artigo:\n",
        "# \"A differential evolution  algorithm with self-adaptive strategy and \n",
        "# control parameters based on symmetric Latin hypercube design for\n",
        "# unconstrained optimization problems\"\n",
        "# Entrada: NP -> número de indivíduos da população população\n",
        "#          d  -> número de variáveis do problema\n",
        "# Saida:             \n",
        "#          m   -> matriz SLHD\n",
        "    \n",
        "  m=np.zeros((NP,d))\n",
        "# SLHD.m:13\n",
        "  for j in np.arange(0,d):\n",
        "      m[0:NP,j]=np.random.permutation(NP)\n",
        "# SLHD.m:15\n",
        "    \n",
        "  flag=np.mod(NP,2)\n",
        "# SLHD.m:18\n",
        "  if flag > 0:\n",
        "      for j in np.arange(0,d):\n",
        "          aux = (NP + 1)//2\n",
        "          #aux.astype(int)\n",
        "          m[aux, j] = (NP+1) / 2\n",
        "# SLHD.m:22\n",
        "    \n",
        "  k=(NP - 1) / 2\n",
        "# SLHD.m:25\n",
        "  k=np.ceil(k)\n",
        "  k = k.astype(int)\n",
        "# SLHD.m:26\n",
        "  phi=np.zeros((k,d))\n",
        "# SLHD.m:27\n",
        "  for j in np.arange(0,d):\n",
        "      phi[0:k,j]=np.random.permutation(k)\n",
        "# SLHD.m:29\n",
        "    \n",
        "  for i in np.arange(0,k):\n",
        "      for j in np.arange(0,d):\n",
        "          if np.random.random(1) < 0.5:\n",
        "            m[i, j] = phi[i, j]\n",
        "# SLHD.m:34\n",
        "            m[NP - (i+1), j] = NP - phi[i, j]\n",
        "# SLHD.m:35\n",
        "          else:\n",
        "            m[i,j] = NP  - phi[i,j]\n",
        "# SLHD.m:37\n",
        "            m[NP - (i+1), j]=phi[i, j]\n",
        "# SLHD.m:38\n",
        "    \n",
        "  m = m / NP\n",
        "# SLHD.m:42\n",
        "  return m"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3RgkCaiCmiM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b009684-e74b-42a4-d7ac-958e316c41d6"
      },
      "source": [
        "print(SLHD(5, 5))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.2 0.2 0.2 0.  0.8]\n",
            " [0.  1.  1.  0.8 0. ]\n",
            " [0.4 0.4 0.  0.2 0.8]\n",
            " [1.  0.  0.  0.2 1. ]\n",
            " [0.8 0.8 0.8 1.  0.2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEUOK3XPNdAR"
      },
      "source": [
        "Function that change the value *tup[ix]*\n",
        " for the value *val*\n",
        "\n",
        " Parameters: \n",
        "      \n",
        "      tup -> the list to be changed\n",
        "      ix -> index to be changed\n",
        "      val -> the value that assigned to *ix* tup possition."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Z1WbsbaNcQA"
      },
      "source": [
        "def replace_at_index1(tup, ix, val):\n",
        "    lst = list(tup)\n",
        "    lst[ix] = val\n",
        "    return tuple(lst)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RixHEXxDVzug",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e21b3ba5-7050-4670-d97c-3659d4276395"
      },
      "source": [
        "%pip install libsvm"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: libsvm in /usr/local/lib/python3.7/dist-packages (3.23.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4sLeoAGVzPw"
      },
      "source": [
        "Parte do código rascunho, usado para entender como usar a LibSVM e criar a função objetivo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4sOaXZ4Plm_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64cb4b50-3b16-4444-cf86-f85fee58ba7d"
      },
      "source": [
        "from libsvm.svmutil import *\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#class data_set:  Criar uma classe para tratar os dados dos bechmarks e tudo mais.\n",
        "# Avaliar se o pandas ou keras ou scklearning.\n",
        "# Não tem um método dentro da pd que faça a separação dos dados em treinamento, validação e teste.\n",
        " \n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
        "new_names = ['sepal_length','sepal_width','petal_length','petal_width','iris_class']\n",
        "dataset = pd.read_csv(url, skiprows=0, delimiter=',')\n",
        "dataset.info()\n",
        "\n",
        "#url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data\"\n",
        "#new_names = ['Radius','Texture','perimeter','area','smoothness', 'compactness', 'concavity', 'concave', 'symmetry', 'fractal']\n",
        "#dataset = pd.read_csv(url, skiprows=0, delimiter=',')\n",
        "#dataset.info()\n",
        " \n",
        "#xx = dataset.values.tolist()\n",
        " \n",
        "#y = dataset.values['iris_class'].tolist()\n",
        " \n",
        "#x = dataset.values['sepal_length'].tolist()\n",
        " \n",
        "#x_list = dataset.values.tolist() #converte para listas\n",
        "x_values = dataset.values #converte para numpy ndarray\n",
        " \n",
        " \n",
        "x = x_values[:, :-1]\n",
        "y1 = x_values[:, -1]\n",
        "\n",
        "print(type(y1))\n",
        " \n",
        "y1 = np.where(y1 == 'Iris-setosa', 0, y1)  \n",
        "y1 = np.where(y1 == 'Iris-virginica', 1, y1)\n",
        "y1 = np.where(y1 == 'Iris-versicolor', 2, y1)\n",
        " \n",
        "\n",
        "m = [0]*15\n",
        "\n",
        "for i in range(10):\n",
        "    \n",
        "    m[i] = []\n",
        "    m[i] = svm_train(y1, x, '-c 40 -t 2 -g .002 -b 1')\n",
        "    sv = m[i].get_nr_sv()\n",
        "    p_label, p_acc, p_val = svm_predict(y1, x, m[i], '-b 1')\n",
        " \n",
        "    #print('Probabilidade de ser um label: ', p_label)\n",
        "    print('Acurácia: ', p_acc)\n",
        "    #print('p_val: ', p_val)\n",
        "    print ('Vetores de suporte', sv)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 149 entries, 0 to 148\n",
            "Data columns (total 5 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   5.1          149 non-null    float64\n",
            " 1   3.5          149 non-null    float64\n",
            " 2   1.4          149 non-null    float64\n",
            " 3   0.2          149 non-null    float64\n",
            " 4   Iris-setosa  149 non-null    object \n",
            "dtypes: float64(4), object(1)\n",
            "memory usage: 5.9+ KB\n",
            "<class 'numpy.ndarray'>\n",
            "Accuracy = 97.3154% (145/149) (classification)\n",
            "Acurácia:  (97.31543624161074, 0.026845637583892617, 0.9599657780050384)\n",
            "Vetores de suporte 52\n",
            "Accuracy = 97.9866% (146/149) (classification)\n",
            "Acurácia:  (97.98657718120806, 0.020134228187919462, 0.9698657903839502)\n",
            "Vetores de suporte 52\n",
            "Accuracy = 97.9866% (146/149) (classification)\n",
            "Acurácia:  (97.98657718120806, 0.020134228187919462, 0.9698657903839502)\n",
            "Vetores de suporte 52\n",
            "Accuracy = 97.9866% (146/149) (classification)\n",
            "Acurácia:  (97.98657718120806, 0.020134228187919462, 0.9698657903839502)\n",
            "Vetores de suporte 52\n",
            "Accuracy = 97.9866% (146/149) (classification)\n",
            "Acurácia:  (97.98657718120806, 0.020134228187919462, 0.9698657903839502)\n",
            "Vetores de suporte 52\n",
            "Accuracy = 97.9866% (146/149) (classification)\n",
            "Acurácia:  (97.98657718120806, 0.020134228187919462, 0.9698657903839502)\n",
            "Vetores de suporte 52\n",
            "Accuracy = 97.9866% (146/149) (classification)\n",
            "Acurácia:  (97.98657718120806, 0.020134228187919462, 0.9698657903839502)\n",
            "Vetores de suporte 52\n",
            "Accuracy = 97.9866% (146/149) (classification)\n",
            "Acurácia:  (97.98657718120806, 0.020134228187919462, 0.9698657903839502)\n",
            "Vetores de suporte 52\n",
            "Accuracy = 97.9866% (146/149) (classification)\n",
            "Acurácia:  (97.98657718120806, 0.020134228187919462, 0.9698657903839502)\n",
            "Vetores de suporte 52\n",
            "Accuracy = 97.3154% (145/149) (classification)\n",
            "Acurácia:  (97.31543624161074, 0.026845637583892617, 0.9599657780050384)\n",
            "Vetores de suporte 52\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJgBMx20heUb"
      },
      "source": [
        "from libsvm.svmutil import *\n",
        "#As particulas devem ter um atributo para armazenar os modelos sendo assim estes disponíveis no final do processo\n",
        "def objective_function(particle_position):     \n",
        "    C = np.exp(particle_position.data[1][0])\n",
        "    g = np.exp(particle_position.data[1][1])\n",
        "    options = '-c ' + str(C) + ' -t 2'  +  ' -g ' + str(g) + ' -b 1'    \n",
        "    m = svm_train(y1, x, options)\n",
        "    p_label, p_acc, p_val = svm_predict(y1, x, m, '-b 1 -q')\n",
        "    sv = m.get_nr_sv()\n",
        "    #return p_acc, sv   #Para funções multi-objetivos.\n",
        "    return float(p_acc[1])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_quATS-nQJb-"
      },
      "source": [
        "def objective_function2(particle_position):\n",
        "    z = 2 * particle_position.data[0][0] + 3 * particle_position.data[0][1] - 2 * particle_position.data[0][2] + \\\n",
        "        particle_position.data[1][0] * particle_position.data[1][1] - particle_position.data[1][2] ** 2 + \\\n",
        "        particle_position.data[1][3] + 8 * particle_position.data[1][4] + 0.5 * particle_position.data[2][0] - \\\n",
        "        particle_position.data[2][1]\n",
        "    return z"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9GbKVd-QLKM"
      },
      "source": [
        "def problem_type(options):\n",
        "    if options.get('problem') == 'min':\n",
        "        mm = -1\n",
        "    else:\n",
        "        mm = 1\n",
        "    return mm"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MM64n5EhQTOQ"
      },
      "source": [
        "def random_dist(options):\n",
        "    if options.get('rand_dist') == 'uniform':  # Return  a uniform distribution random number in the range [0.0, 1)\n",
        "        r1 = random.random()\n",
        "        r2 = random.random()\n",
        " \n",
        "    elif options.get(\n",
        "            'rand_dist') == 'gauss':  # Return a gaussian distribution with mean zero and standart desviation 0.5\n",
        "        r1 = random.gauss(0, 0.5)\n",
        "        r2 = random.gauss(0, 0.5)\n",
        "    return r1, r2"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BM8bhGRQUjm"
      },
      "source": [
        "def inertia_coef(options, i):\n",
        "    if options.get('inertia') == 'costant':\n",
        "        w = 0.8\n",
        "        return w\n",
        "    if options.get('inertia')[0] == 'linear':\n",
        "        t = options.get('iterations')\n",
        "        wc = options.get('inertia')[1]\n",
        "        w = (wc[1] - wc[0]) / t * (i - wc[0]) + wc[0]\n",
        "        return w"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LswaqaUWSD55"
      },
      "source": [
        "# Particle Swarm Optimization - PSO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfkVbe-gQl9B"
      },
      "source": [
        "class Particle_type:\n",
        "    # type_vars é um dicionário com os tipos e a dimensão de cada tipo. Ex.: type_vars = {'float':5, 'int': 10}\n",
        "    # bounds é um dicionário que contem listas com limites inferiores e superiores das variáveis de decisão.\n",
        "    def __init__(self, type_vars, bounds):\n",
        "        self.type_vars = type_vars  # Armazena o tipo da partícula para controle e futuras aplicações no código.\n",
        "        self.data = [0] * len(type_vars)\n",
        "        self.bounds = [0] * len(type_vars)\n",
        "        i = 0\n",
        "        for type_key in type_vars.keys():\n",
        "            self.data[i] = [0] * type_vars.get(type_key)\n",
        "            self.bounds [i] = [0] * type_vars.get(type_key)\n",
        "            for j in range(type_vars.get(type_key)):            \n",
        "                self.bounds[i][j] = [0, 0] #Acredito que já poderia ser direto aqui, sem o monte de if for a seguir!\n",
        "            i = i + 1        \n",
        "        j = 0\n",
        "        for type_key in type_vars.keys():  # Percorre o dicionário de tipos\n",
        "            if type_key == 'float':\n",
        "                for i in range(type_vars.get(type_key)):  # Percorre cada posição da lista tipo float\n",
        "                    self.bounds[j][i][0] = bounds['float_b'][i][0]  # Atribui os valoes aleatórios de acordo com a distribuição desejada (criar uma função para isso)\n",
        "                    self.bounds[j][i][1] = bounds['float_b'][i][1]  # Atribui os valoes aleatórios de acordo com a distribuição desejada (criar uma função para isso)\n",
        "                j = j + 1\n",
        "            if type_key == 'int':\n",
        "                for i in range(type_vars.get(type_key)):  # Percorre cada posição da lista tipo int\n",
        "                    self.bounds[j][i][0] = bounds['int_b'][i][0]  # Atribui os valoes aleatórios de acordo com a distribuição desejada (criar uma função para isso)\n",
        "                    self.bounds[j][i][1] = bounds['int_b'][i][1]  # Atribui os valoes aleatórios de acordo com a distribuição desejada (criar uma função para isso)                    \n",
        "                j = j + 1\n",
        "            if type_key == 'bin':\n",
        "                for i in range(type_vars.get(type_key)):  # Percorre cada posição da lista tipo bin                    \n",
        "                    self.bounds[j][i][0] = bounds['bin_b'][i][0]  # Atribui os valoes aleatórios de acordo com a distribuição desejada (criar uma função para isso)\n",
        "                    self.bounds[j][i][1] = bounds['bin_b'][i][1]  # Atribui os valoes aleatórios de acordo com a distribuição desejada (criar uma função para isso)                    \n",
        "                    #print('Particle limites: ', self.bounds[j][i])\n",
        "                j = j + 1\n",
        "            if type_key == 'kernel':\n",
        "                for i in range(type_vars.get(type_key)):  # Percorre cada posição da lista tipo kernel\n",
        "                    self.bounds = bounds['bin_b']  # Atribui os valoes aleatórios de acordo com a distribuição desejada (criar uma função para isso)\n",
        "                j = j + 1\n",
        "        \n",
        "    \n",
        "    def initialize_values(self, type_vars, options): \n",
        "        j = 0  # conta a posição do tipo no dicionário\n",
        "        for type_key in type_vars.keys():  # Percorre o dicionário de tipos\n",
        "            if type_key == 'float':  # Identifica o tipo float\n",
        "                for i in range(type_vars.get(type_key)):  # Percorre cada posição da lista tipo float\n",
        "                    #print(j, i)\n",
        "                    #print (self.bounds)\n",
        "                    self.data[j][i] = random.uniform(self.bounds[j][i][0], self.bounds[j][i][1])  # Atribui os valoes aleatórios de acordo com a distribuição desejada (criar uma função para isso)\n",
        "                j = j + 1\n",
        " \n",
        "            if type_key == 'int':  # Identifica o tipo int\n",
        "                for i in range(type_vars.get(type_key)):  # Percorre cada posição da lista tipo int\n",
        "                    self.data[j][i] = random.randint(self.bounds[j][i][0], self.bounds[j][i][1])  # Atribui os valoes aleatórios de acordo com a distribuição desejada (criar uma função para isso)\n",
        "                j = j + 1\n",
        " \n",
        "            if type_key == 'bin':  # Identifica o tipo bin\n",
        "                for i in range(type_vars.get(type_key)):  # Percorre cada posição da lista tipo bin\n",
        "                    #self.data[j][i] = bool(random.randint(0,1))  # Atribui os valoes aleatórios de acordo com a distribuição desejada (criar uma função para isso)\n",
        "                    self.data[j][i] = random.randint(0,1)  # Atribui os valoes aleatórios de acordo com a distribuição desejada (criar uma função para isso)\n",
        "                j = j + 1\n",
        " \n",
        "            if type_key == 'kernel':  # Identifica o tipo kernel\n",
        "                for i in range(type_vars.get(type_key)):  # Percorre cada posição da lista tipo bin\n",
        "                    self.data[j][i] = random.randint(0,1)  # Atribui os valoes aleatórios de acordo com a distribuição desejada (criar uma função para isso)\n",
        "                j = j + 1\n",
        " \n",
        "            # _-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qjMe_7hTXfc"
      },
      "source": [
        "Classe que cria e manipula as partículas do PSO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpv2YxM5Qz6r"
      },
      "source": [
        "# Classe que cria as partículas do PSO\n",
        "class Particle:\n",
        "    def __init__(self, bounds, dict_type, options, objective_function):\n",
        "        self.particle_position = Particle_type(dict_type, bounds)  # particle position\n",
        "        self.particle_velocity = Particle_type(dict_type, bounds)  # particle velocity\n",
        "        self.local_best_particle_position = Particle_type(dict_type, bounds)  # best position of the particle\n",
        "        self.fitness_local_best_particle = options.get('initial_fitness')  # initial objective function value of the best particle position\n",
        "        self.fitness_particle = options.get('initial_fitness')  # objective function value of the particle position\n",
        "        self.data_type = dict_type  # the particle type.\n",
        "        self.particle_position.initialize_values( dict_type, options)\n",
        "        self.particle_velocity.initialize_values( dict_type, options)\n",
        " \n",
        "        self.evaluate(objective_function, options)\n",
        " \n",
        "    def evaluate(self, objective_function, options):    \n",
        "        self.fitness_particle = objective_function(self.particle_position)\n",
        "        \n",
        "        if problem_type(options) == -1:\n",
        "            #print(self.fitness_particle)\n",
        "            if self.fitness_particle < self.fitness_local_best_particle:\n",
        "                self.local_best_particle_position = self.particle_position  # update the local best\n",
        "                self.fitness_local_best_particle = self.fitness_particle  # update the fitness of the local best\n",
        "                \n",
        "        if problem_type(options) == 1:\n",
        "            if self.fitness_particle > self.fitness_local_best_particle:\n",
        "                self.local_best_particle_position = self.particle_position  # update the local best\n",
        "                self.fitness_local_best_particle = self.fitness_particle  # update the fitness of the local best\n",
        " \n",
        "    def update_velocity(self, global_best_particle, options):  # global_best_particle ->  a variável do tipo partícula (melhor partícula da população)\n",
        "        coef = options.get('coeficients')\n",
        "        j = 0  # conta a posição do tipo no dicionário\n",
        "        for type_key in self.data_type.keys():  # Percorre o dicionário de tipos\n",
        "            if type_key == 'float':  # Identifica o tipo float\n",
        "                for i in range(self.data_type.get(type_key)):  # Percorre cada posição da lista tipo float\n",
        "                    r1, r2 = random_dist(options)\n",
        "                    cognitive_velocity = coef[0] * r1 * (self.local_best_particle_position.data[j][i] - self.particle_position.data[j][i])\n",
        "                    social_velocity = coef[1] * r2 * (global_best_particle.particle_position.data[j][i] - self.particle_position.data[j][i])\n",
        "                    self.particle_velocity.data[j][i] = inertia_coef(options, 1) * self.particle_velocity.data[j][i] + cognitive_velocity + social_velocity  # Atribui os valoes aleatórios de acordo com a distribuição desejada (criar uma função para isso)\n",
        "                j = j + 1\n",
        " \n",
        "            if type_key == 'int':  # Identifica o tipo int\n",
        "                for i in range(self.data_type.get(\n",
        "                        type_key)):  # Percorre cada posição da lista tipo int\n",
        "                    r1, r2 = random_dist(options)\n",
        "                    cognitive_velocity = coef[0] * r1 * (self.local_best_particle_position.data[j][i] - self.particle_position.data[j][i])\n",
        "                    social_velocity = coef[1] * r2 * (global_best_particle.particle_position.data[j][i] - self.particle_position.data[j][i])\n",
        "                    self.particle_velocity.data[j][i] = inertia_coef(options, 1) * self.particle_velocity.data[j][i] + cognitive_velocity + social_velocity  # Atribui os valoes aleatórios de acordo com a distribuição desejada (criar uma função para isso)\n",
        "                j = j + 1\n",
        " \n",
        "            if type_key == 'bin':  # Identifica o tipo bin\n",
        "                for i in range(self.data_type.get(type_key)):  # Percorre cada posição da lista tipo bin\n",
        "                    r1, r2 = random_dist(options)\n",
        "                    cognitive_velocity = coef[0] * r1 * (\n",
        "                                self.local_best_particle_position.data[j][i] - self.particle_position.data[j][i])\n",
        "                    social_velocity = coef[1] * r2 * (global_best_particle.particle_position.data[j][i] - self.particle_position.data[j][i])\n",
        "                    self.particle_velocity.data[j][i] = inertia_coef(options, 1) * self.particle_velocity.data[j][i] + cognitive_velocity + social_velocity  # Atribui os valoes aleatórios de acordo com a distribuição desejada (criar uma função para isso)\n",
        "                j = j + 1\n",
        " \n",
        "            if type_key == 'kernel':  # Identifica o tipo kernel\n",
        "                for i in range(\n",
        "                        self.data_type.get(type_key)):  # Percorre cada posição da lista tipo bin\n",
        "                    r1, r2 = random_dist(options)\n",
        "                    cognitive_velocity = coef[0] * r1 * (\n",
        "                                self.local_best_particle_position.data[j][i] - self.particle_position.data[j][i])\n",
        "                    social_velocity = coef[1] * r2 * (\n",
        "                                global_best_particle.particle_position.data[j][i] - self.particle_position.data[j][i])\n",
        "                    self.particle_velocity.data[j][i] = inertia_coef(options, 1) * self.particle_velocity.data[j][\n",
        "                        i] + cognitive_velocity + social_velocity  # Atribui os valoes aleatórios de acordo com a distribuição desejada (criar uma função para isso)\n",
        "                j = j + 1\n",
        " \n",
        "    def update_position(self):\n",
        "        j = 0  # conta a posição do tipo no dicionário\n",
        "        for type_key in self.data_type.keys():  # Percorre o dicionário de tipos\n",
        "            if type_key == 'float':  # Identifica o tipo float\n",
        "                for i in range(self.data_type.get(type_key)):  # Percorre cada posição da lista tipo float\n",
        "                    #print('Valor de j: ', j, 'Valor de i: ', i)\n",
        "                    #print(self.particle_position.data[j][i])\n",
        "                    #print(self.particle_velocity.data[j][i])\n",
        "                    #print('Particle bounds:', self.particle_position.bounds) \n",
        "                    self.particle_position.data[j][i] = self.particle_position.data[j][i] +  self.particle_velocity.data[j][i]\n",
        "                    if self.particle_position.data[j][i] < self.particle_position.bounds[j][i][0]:\n",
        "                      self.particle_position.data[j][i] = self.particle_position.bounds[j][i][0]\n",
        " \n",
        "                    elif self.particle_position.data[j][i] > self.particle_position.bounds[j][i][1]:\n",
        "                      self.particle_position.data[j][i] = self.particle_position.bounds[j][i][1]\n",
        "                j = j + 1         \n",
        "            if type_key == 'int':  # Identifica o tipo int\n",
        "                for i in range(self.data_type.get(type_key)):  # Percorre cada posição da lista tipo int\n",
        "                    self.particle_position.data[j][i] = self.particle_position.data[j][i] +  self.particle_velocity.data[j][i]\n",
        "                    if self.particle_position.data[j][i] < self.particle_position.bounds[j][i][0]:\n",
        "                      self.particle_position.data[j][i] = self.particle_position.bounds[j][i][0]\n",
        " \n",
        "                    elif self.particle_position.data[j][i] > self.particle_position.bounds[j][i][1]:\n",
        "                      self.particle_position.data[j][i] = self.particle_position.bounds[j][i][1]\n",
        "                j = j + 1\n",
        " \n",
        "            if type_key == 'bin':  # Identifica o tipo bin\n",
        "                for i in range(self.data_type.get(type_key)):  # Percorre cada posição da lista tipo bin\n",
        "                    self.particle_position.data[j][i] = self.particle_position.data[j][i] +  self.particle_velocity.data[j][i]\n",
        "                    if self.particle_position.data[j][i] <= 0: #self.particle_position.bounds[0][i]: #o operador de vetores binários para a velocidade e posição precisa ser melhor analisado (ver literatura)\n",
        "                      self.particle_position.data[j][i] =  0 #self.particle_position.bounds[0][i]\n",
        " \n",
        "                    elif self.particle_position.data[j][i] >= 1: #self.particle_position.bounds[1][i]:\n",
        "                      self.particle_position.data[j][i] = 1\n",
        "                j = j + 1\n",
        "            #print(self.particle_position.data)\n",
        " \n",
        "            if type_key == 'kernel':  # Identifica o tipo kernel\n",
        "                for i in range(self.data_type.get(type_key)):  # Percorre cada posição da lista tipo kernel\n",
        "                    self.particle_position.data[j][i] = self.particle_position.data[j][i] +  self.particle_velocity.data[j][i]\n",
        "                    if self.particle_position.data[j][i] < self.particle_position.bounds[j][i][0]:\n",
        "                      self.particle_position.data[j][i] = self.particle_position.bounds[j][i][0]\n",
        " \n",
        "                    elif self.particle_position.data[j][i] > self.particle_position.bounds[j][i][1]:\n",
        "                      self.particle_position.data[j][i] = self.particle_position.bounds[j][i][1]\n",
        "                j = j + 1"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNqoLPNzTy4X"
      },
      "source": [
        "Classe que manipula a população do PSO.\n",
        "\n",
        "Esta classe permite que seja criada populações diferentes com comportamentos diferentes e ter acesso ao melhor posição global."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zk3n_V0tQ2cd"
      },
      "source": [
        "class Population:\n",
        "    def __init__(self, bounds, dict_type, options, objective_function):\n",
        "        self.particles = [[] for item in range(options.get('Population'))]\n",
        " \n",
        "        for i in range(options.get('Population')):\n",
        "            self.particles[i] = Particle(bounds, dict_type, options, objective_function)\n",
        " \n",
        "        self.global_best_particle = Particle(bounds, dict_type, options, objective_function)\n",
        "        self.global_best_particle.fitness_local_best_particle = options.get('initial_fitness')  # initial objective function value of the best particle position                \n",
        "        self.global_best_particle.fitness_particle = options.get('initial_fitness')  # objective function value of the particle position\n",
        "        self.global_best()\n",
        "        \n",
        " \n",
        "    def global_best(self):\n",
        "        for i in range(options.get('Population')):\n",
        "            if (problem_type(options) == -1):\n",
        "                if (self.particles[i].fitness_particle <= self.global_best_particle.fitness_particle):                    \n",
        "                    self.global_best_particle = self.particles[i]            \n",
        " \n",
        "            elif (problem_type(options) == 1):\n",
        "                if (self.particles[i].fitness_particle >= self.global_best_particle.fitness_particle):\n",
        "                    self.global_best_particle = self.particles[i]\n",
        "        return self.global_best_particle.fitness_particle\n",
        " \n",
        "    def print_particles_position(self):\n",
        "        for i in range(options.get('Population')):\n",
        "            print(f'Index: {i} Particle: {self.particles[i].particle_position.data}')\n",
        " \n",
        "    def print_particles_velocity(self):\n",
        "        for i in range(options.get('Population')):\n",
        "            print(f'Index: {i} Velocity: {self.particles[i].particle_velocity.data}')            \n",
        " \n",
        "    def print_particles_fitness(self):\n",
        "        for i in range(options.get('Population')):\n",
        "            print(f'Index: {i} Fitness: {self.particles[i].fitness_particle}')\n",
        " \n",
        "    def print_global(self):\n",
        "        print(f'Global best: {self.global_best_particle.fitness_particle}')\n",
        "        print(f'Particle position: {self.global_best_particle.particle_position.data}')        "
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFeBDljgRBlG"
      },
      "source": [
        "Parte do código que chama as funções e classes.\n",
        "\n",
        "Esta célula é provisória"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUCJJETc8t5l"
      },
      "source": [
        "#Execução: Teste do sistema"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvgSCujjRArd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e30364a9-bc39-4925-d4a4-85dd76e4aea4"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "tipo_x = {'bin': 3, 'float': 2, 'int': 2}\n",
        "options = {'inertia': ['linear', (0.5, 0.1)], 'initial_fitness': float('inf'), 'iterations': 15, 'rand_dist': 'uniform',\n",
        "           'problem': 'min', 'coeficients': (2.1, 2.1), 'Population': 5}\n",
        "#mudar a estrutura dos limites para o mesmo formato das partículas, verificar saída desta célula.\n",
        "#limites = [(0, 0, 0, -7, -6, -8, -4, -11, -5, -3, -8), (1, 1, 1, 7, 6, 8, 4, 11, 5, 3, 8)]\n",
        "#limites = {'bin_b': [[0, 0, 0], [1, 1, 1]], 'float_b': [[-7, -6, -8, -4, -11], [7, 6, 8, 4, 11]], 'int_b': [[-5, -3], [5, 3]]}\n",
        "limites = {'bin_b': [[0, 1],[0, 1], [0, 1]], 'float_b': [[-20, 20],[-25, 25]], 'int_b': [[-5, 5], [-3, 3]]}\n",
        "#print(limites ['float_b'][1][0])\n",
        "x1 = Particle_type(tipo_x, limites)\n",
        " \n",
        "# Executando o PSO básico\n",
        "#População inicial\n",
        "population = Population(limites, tipo_x, options, objective_function)\n",
        "population.global_best()\n",
        " \n",
        "for i in range(options.get('iterations')):\n",
        "#Atualiza a velocidade da população inicial  \n",
        "  for j in range (options.get('Population')):\n",
        "    population.particles[j].update_velocity(population.global_best_particle, options)\n",
        "    population.particles[j].evaluate(objective_function, options)\n",
        "    population.particles[j].update_position()\n",
        "    population.global_best()\n",
        "  population.print_particles_position()\n",
        "  #population.print_particles_velocity()\n",
        "  #population.print_particles_fitness()\n",
        "population.print_global()\n",
        "\n",
        " \n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index: 0 Particle: [[1, 1, 1], [20, 15.12523857554512], [2.937790308689311, 0.5233781484233487]]\n",
            "Index: 1 Particle: [[1, 0.7544803871963264, 1], [4.243408999205424, 25], [3.6932156823776108, 2.605760544587797]]\n",
            "Index: 2 Particle: [[1, 1, 1], [9.920971944697005, 9.181662860477799], [4.46, 2.9733333333333336]]\n",
            "Index: 3 Particle: [[1, 1, 1], [6.3781621461130555, 8.533247174540623], [5, 2.3593288958270513]]\n",
            "Index: 4 Particle: [[1, 0.07843793313633933, 1], [9.49476016330145, 25], [-4.7656205655246096, 3]]\n",
            "Index: 0 Particle: [[1, 1, 1], [20, 16.135319499269933], [5, 1.7419227145418965]]\n",
            "Index: 1 Particle: [[1, 1, 1], [5.7225474472177025, 25], [5, 3]]\n",
            "Index: 2 Particle: [[1, 1, 1], [7.28174790666562, 6.311687391770486], [5, 3]]\n",
            "Index: 3 Particle: [[1, 1, 1], [10.174751213936334, 10.649518368370943], [5, 3]]\n",
            "Index: 4 Particle: [[1, 0.2072421551126739, 1], [12.340783895584146, 25], [5, 3]]\n",
            "Index: 0 Particle: [[1, 1, 1], [20, 6.734745135905708], [5, 3]]\n",
            "Index: 1 Particle: [[1, 1, 1], [7.726087263606891, 25], [5, 3]]\n",
            "Index: 2 Particle: [[1, 1, 1], [10.742426541898421, 8.98597836398684], [5, 3]]\n",
            "Index: 3 Particle: [[1, 1, 1], [12.022424560276995, 11.679437016035033], [5, 3]]\n",
            "Index: 4 Particle: [[1, 1, 1], [11.651680789869907, 25], [5, 3]]\n",
            "Index: 0 Particle: [[1, 1, 1], [18.754429508475916, 25], [5, 3]]\n",
            "Index: 1 Particle: [[1, 1, 1], [13.091855042619555, 25], [5, 3]]\n",
            "Index: 2 Particle: [[1, 1, 1], [13.788058729806258, 25], [5, 3]]\n",
            "Index: 3 Particle: [[1, 1, 1], [12.74995688585201, 23.132281679402638], [5, 3]]\n",
            "Index: 4 Particle: [[1, 1, 1], [11.31631727842231, 25], [5, 3]]\n",
            "Index: 0 Particle: [[1, 1, 1], [17.67844021078705, 25], [5, 3]]\n",
            "Index: 1 Particle: [[1, 1, 1], [15.11122519426588, 24.95648996300353], [5, 3]]\n",
            "Index: 2 Particle: [[1, 1, 1], [13.720335350483257, 25], [5, 3]]\n",
            "Index: 3 Particle: [[1, 1, 1], [13.10402261763185, 25], [5, 3]]\n",
            "Index: 4 Particle: [[1, 1, 1], [11.184953096252245, 25], [5, 3]]\n",
            "Index: 0 Particle: [[1, 1, 1], [11.405305624386486, 25], [5, 3]]\n",
            "Index: 1 Particle: [[1, 1, 1], [13.733275215880866, 24.998474577812125], [5, 3]]\n",
            "Index: 2 Particle: [[1, 1, 1], [13.139296602415467, 25], [5, 3]]\n",
            "Index: 3 Particle: [[1, 1, 1], [13.27633460709804, 25], [5, 3]]\n",
            "Index: 4 Particle: [[1, 1, 1], [11.267064049226322, 25], [5, 3]]\n",
            "Index: 0 Particle: [[1, 1, 1], [8.32564786311381, 25], [5, 3]]\n",
            "Index: 1 Particle: [[1, 1, 1], [10.771654339745742, 25], [5, 3]]\n",
            "Index: 2 Particle: [[1, 1, 1], [11.560968577236961, 25], [5, 3]]\n",
            "Index: 3 Particle: [[1, 1, 1], [10.332719702970184, 25], [5, 3]]\n",
            "Index: 4 Particle: [[1, 1, 1], [11.307024713007038, 25], [5, 3]]\n",
            "Index: 0 Particle: [[1, 1, 1], [8.045739985944625, 25], [5, 3]]\n",
            "Index: 1 Particle: [[1, 1, 1], [10.362957363472463, 25], [5, 3]]\n",
            "Index: 2 Particle: [[1, 1, 1], [10.41980714374764, 25], [5, 3]]\n",
            "Index: 3 Particle: [[1, 1, 1], [10.560543240497825, 25], [5, 3]]\n",
            "Index: 4 Particle: [[1, 1, 1], [11.326472236046987, 25], [5, 3]]\n",
            "Index: 0 Particle: [[1, 1, 1], [13.355345418942292, 25], [5, 3]]\n",
            "Index: 1 Particle: [[1, 1, 1], [10.861677163713665, 25], [5, 3]]\n",
            "Index: 2 Particle: [[1, 1, 1], [10.82119857880789, 25], [5, 3]]\n",
            "Index: 3 Particle: [[1, 1, 1], [10.917990951204636, 25], [5, 3]]\n",
            "Index: 4 Particle: [[1, 1, 1], [11.335936697259763, 25], [5, 3]]\n",
            "Index: 0 Particle: [[1, 1, 1], [13.140155326049133, 25], [5, 3]]\n",
            "Index: 1 Particle: [[1, 1, 1], [11.159597000238724, 25], [5, 3]]\n",
            "Index: 2 Particle: [[1, 1, 1], [11.163374370577896, 25], [5, 3]]\n",
            "Index: 3 Particle: [[1, 1, 1], [11.09194883708195, 25], [5, 3]]\n",
            "Index: 4 Particle: [[1, 1, 1], [11.282711414104941, 25], [5, 3]]\n",
            "Index: 0 Particle: [[1, 1, 1], [12.522201620552948, 25], [5, 3]]\n",
            "Index: 1 Particle: [[1, 1, 1], [11.351407332917292, 25], [5, 3]]\n",
            "Index: 2 Particle: [[1, 1, 1], [11.434583568549357, 25], [5, 3]]\n",
            "Index: 3 Particle: [[1, 1, 1], [11.35881622757296, 25], [5, 3]]\n",
            "Index: 4 Particle: [[1, 1, 1], [11.256808442969595, 25], [5, 3]]\n",
            "Index: 0 Particle: [[1, 1, 1], [10.635387896236502, 25], [5, 3]]\n",
            "Index: 1 Particle: [[1, 1, 1], [11.451980150697267, 25], [5, 3]]\n",
            "Index: 2 Particle: [[1, 1, 1], [11.411370045288008, 25], [5, 3]]\n",
            "Index: 3 Particle: [[1, 1, 1], [11.488691690945252, 25], [5, 3]]\n",
            "Index: 4 Particle: [[1, 1, 1], [11.438606603356774, 25], [5, 3]]\n",
            "Index: 0 Particle: [[1, 1, 1], [10.004176277650567, 25], [5, 3]]\n",
            "Index: 1 Particle: [[1, 1, 1], [11.46539310555541, 25], [5, 3]]\n",
            "Index: 2 Particle: [[1, 1, 1], [11.400072797300819, 25], [5, 3]]\n",
            "Index: 3 Particle: [[1, 1, 1], [11.476657777297405, 25], [5, 3]]\n",
            "Index: 4 Particle: [[1, 1, 1], [11.59048412379133, 25], [5, 3]]\n",
            "Index: 0 Particle: [[1, 1, 1], [10.700930271220496, 25], [5, 3]]\n",
            "Index: 1 Particle: [[1, 1, 1], [11.567561725005952, 25], [5, 3]]\n",
            "Index: 2 Particle: [[1, 1, 1], [11.696957231207218, 25], [5, 3]]\n",
            "Index: 3 Particle: [[1, 1, 1], [11.703020680080455, 25], [5, 3]]\n",
            "Index: 4 Particle: [[1, 1, 1], [11.664397850402812, 25], [5, 3]]\n",
            "Index: 0 Particle: [[1, 1, 1], [12.775358160026123, 25], [5, 3]]\n",
            "Index: 1 Particle: [[1, 1, 1], [11.67833072777157, 25], [5, 3]]\n",
            "Index: 2 Particle: [[1, 1, 1], [11.803092267470912, 25], [5, 3]]\n",
            "Index: 3 Particle: [[1, 1, 1], [11.75625525333072, 25], [5, 3]]\n",
            "Index: 4 Particle: [[1, 1, 1], [11.700369197353734, 25], [5, 3]]\n",
            "Global best: 0.0\n",
            "Particle position: [[1, 1, 1], [11.700369197353734, 25], [5, 3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1c5LxjCbwIL"
      },
      "source": [
        "Tarefas a realizar:\n",
        "\n",
        "1) Criar um git para o projeto.\n",
        "\n",
        "2) Criar índices dentro da população para cada partícula.\n",
        "\n",
        "3) Não há como operar partículas com kernels diferentes, pois os tamanhos das listas são diferentes e representam \"coisas diferentes\" (Projeto futuro).\n",
        "\n",
        "4) Gerar uma biblioteca para o sistema.\n",
        "\n",
        "5) Implementar a opção de SVR.\n",
        "\n",
        "6) Pode-se resolver o problema dos kernels com subpopulações.\n",
        "\n",
        "7) Implementar a opção de kernel escolhido pelo usuário, como no NIOTS do Matlab."
      ]
    }
  ]
}